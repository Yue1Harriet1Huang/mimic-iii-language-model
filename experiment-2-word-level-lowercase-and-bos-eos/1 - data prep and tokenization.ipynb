{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - LM with Sampled Data, Lowercased with BOS/EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "import html\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "EOS = 'xeos'  # data field tag\n",
    "\n",
    "PATH=Path('/home/paperspace/data/mimic-iii')\n",
    "LM_PATH=PATH/'exp-2'\n",
    "\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH/'NOTEEVENTS.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = df.TEXT.str.lower().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(\n",
    "    notes, test_size=0.1)\n",
    "\n",
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=['labels','text'])\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=['labels','text'])\n",
    "\n",
    "df_trn['text'] = df_trn.text.str.replace('\\n','')\n",
    "df_val['text'] = df_val.text.str.replace('\\n','')\n",
    "\n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=True, index=False)\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(LM_PATH/'train.csv', chunksize=chunksize, engine='python')\n",
    "df_val = pd.read_csv(LM_PATH/'test.csv', chunksize=chunksize, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df):\n",
    "    texts = f'\\n{BOS} ' + df.text.astype(str) + f' {EOS}'\n",
    "    tok = Tokenizer.proc_all_mp(partition_by_cores(texts), lang='en')\n",
    "    return tok\n",
    "\n",
    "def get_all(df, name):\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_  = get_texts(r)\n",
    "        #save the partial tokens instead of regrouping them in one big array.\n",
    "        np.save(LM_PATH/f'{name}_tok{i}.npy', tok_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "get_all(df_trn,'trn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "get_all(df_val,'tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_them_all(names):\n",
    "    cnt = Counter()\n",
    "    for name in names:\n",
    "        for file in LM_PATH.glob(f'{name}_tok*'):\n",
    "            tok = np.load(file)\n",
    "            cnt_tok = Counter(word for sent in tok for word in sent)\n",
    "            cnt += cnt_tok\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = count_them_all(['trn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('*', 38382786),\n",
       " ('.', 27018846),\n",
       " (':', 20976834),\n",
       " (',', 18188128),\n",
       " ('-', 16487644),\n",
       " ('/', 12633658),\n",
       " (']', 9740260),\n",
       " ('[', 9400807),\n",
       " ('and', 7999520),\n",
       " (')', 7949283),\n",
       " ('(', 7537086),\n",
       " ('to', 7340443),\n",
       " ('the', 7096614),\n",
       " ('of', 6447552),\n",
       " ('with', 5605332),\n",
       " ('for', 4195069),\n",
       " ('in', 4139239),\n",
       " ('is', 3669299),\n",
       " ('on', 3496859),\n",
       " ('no', 3449699),\n",
       " ('a', 2521034),\n",
       " ('was', 2271430),\n",
       " ('pt', 2207854),\n",
       " ('at', 2149678),\n",
       " ('2', 2006607),\n",
       " ('1', 1905333),\n",
       " ('am', 1879485),\n",
       " ('mg', 1873696),\n",
       " ('\\n', 1676109),\n",
       " ('xbos', 1674985),\n",
       " ('xeos', 1674985),\n",
       " ('%', 1636825),\n",
       " ('left', 1600425),\n",
       " ('#', 1598717),\n",
       " ('this', 1593269),\n",
       " ('as', 1583053),\n",
       " ('name', 1569413),\n",
       " ('ml', 1511484),\n",
       " ('right', 1471611),\n",
       " ('3', 1331350),\n",
       " ('not', 1289241),\n",
       " ('patient', 1239536),\n",
       " ('there', 1204960),\n",
       " ('4', 1197226),\n",
       " ('last', 1194902),\n",
       " ('are', 1188600),\n",
       " ('tk_rep', 1181862),\n",
       " ('5', 1178812),\n",
       " ('or', 1176187),\n",
       " ('pm', 1159586)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in cnt.most_common(max_vocab) if c > min_freq]\n",
    "itos.insert(0,'_pad_')\n",
    "itos.insert(0,'_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(int,{s:i for (i,s) in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(name, partial=True):\n",
    "    results = []\n",
    "    for index, file in enumerate(LM_PATH.glob(f'{name}_tok*')):\n",
    "        print(index)\n",
    "        tok = np.load(file)\n",
    "        results.append(np.array([[stoi[word] for word in sent] for sent in tok]))\n",
    "        \n",
    "        if (index == 10) and (partial==True):\n",
    "            break\n",
    "\n",
    "    return np.concatenate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "trn_ids = numericalize('trn')\n",
    "np.save(LM_PATH/'trn_ids.npy', trn_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "val_ids = numericalize('tst')\n",
    "np.save(LM_PATH/'val_ids.npy', val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LM_PATH/'itos.pickle', 'wb') as handle:\n",
    "    pickle.dump(itos, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LM_PATH/'stoi.pickle', 'wb') as handle:\n",
    "    pickle.dump(stoi, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = np.load(LM_PATH/'trn_ids.npy')\n",
    "np.save(LM_PATH/'trn_ids_concat.npy', np.concatenate(trn_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = np.load(LM_PATH/'val_ids.npy')\n",
    "np.save(LM_PATH/'val_ids_concat.npy', np.concatenate(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
