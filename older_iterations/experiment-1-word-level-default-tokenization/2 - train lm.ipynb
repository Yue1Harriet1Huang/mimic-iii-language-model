{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('/home/paperspace/data/mimic-iii')\n",
    "LM_PATH=PATH/'lm_word_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = np.load(LM_PATH/'trn_ids_concat.npy')\n",
    "val_ids = np.load(LM_PATH/'val_ids_concat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LM_PATH/'itos.pickle', 'rb') as handle:\n",
    "    itos = pickle.load(handle)\n",
    "    \n",
    "vocab_size=len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3\n",
    "bptt, bs = 70, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(trn_ids, bs, bptt)\n",
    "val_dl = LanguageModelLoader(val_ids, bs, bptt)\n",
    "md = LanguageModelData(PATH, 0, vocab_size, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8,0.99))\n",
    "learner= md.get_model(opt_fn, em_sz, nh, nl,\n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "learner.metrics = [accuracy]\n",
    "learner.clip=0.12\n",
    "learner.unfreeze()\n",
    "learner.reg_fn=partial(seq2seq_reg, alpha=2, beta=1)\n",
    "wd = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(end_lr=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 10e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9ff4f3262840d7997cdb2959826703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                         \n",
      "    0      2.635664   2.427942   0.540275  \n",
      "    1      2.551668   2.369839   0.547285                         \n",
      "    2      2.572614   2.381757   0.546985                         \n",
      "    3      2.568972   2.412489   0.543766                         \n",
      "    4      2.614528   2.41644    0.543442                         \n",
      "    5      2.539698   2.358792   0.550942                         \n",
      "    6      2.484577   2.30351    0.558644                         \n",
      "    7      2.431909   2.254647   0.565642                         \n",
      "    8      2.387832   2.215251   0.571395                         \n",
      "    9      2.359126   2.19928    0.573917                         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.19928]), 0.5739172494452303]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lr, 1, cycle_len=10, use_clr_beta=(10,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot_loss(n_skip=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('word_level_default_tokenization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('word_level_default_tokenization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learner.model\n",
    "\n",
    "with open(LM_PATH/'stoi.pickle','rb') as f:\n",
    "    stoi = pickle.load(f)\n",
    "\n",
    "def sample_model(m, s, l=100):\n",
    "    s_toks = Tokenizer().proc_text(s)\n",
    "    s_nums = [stoi[i] for i in s_toks]\n",
    "    s_var = V(np.array(s_nums))[None]\n",
    "\n",
    "    m[0].bs=1\n",
    "    m.eval()\n",
    "    m.reset()\n",
    "\n",
    "    res, *_ = m(s_var)\n",
    "    print('...', end='')\n",
    "\n",
    "    for i in range(l):\n",
    "        r = torch.multinomial(res[-1].exp(), 2)\n",
    "        #r = torch.topk(res[-1].exp(), 2)[1]\n",
    "        if r.data[0] == 0:\n",
    "            r = r[1]\n",
    "        else:\n",
    "            r = r[0]\n",
    "        \n",
    "        word = itos[to_np(r)[0]]\n",
    "        res, *_ = m(r[0].unsqueeze(0))\n",
    "        print(word, end=' ')\n",
    "    m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..., deviation.non-specific occulsion for cardiac resection . lastname * * ] now her prognosis is slightly difficult for d / c to rehab if patient can not recover - i c [ * * name8 ( md ) 24 * * ] team care . t_up events - dc po abx as patient on glargine drip for trach t_up icu care nutrition : tfs continues , sedation / t_up npo for procedure glycemic control : insulin sliding scale lines : multi lumen - [ * * 2156 - 12 - 28 * * ] 08:26 pm dialysis catheter - [ "
     ]
    }
   ],
   "source": [
    "s = 'cardiovascular system '\n",
    "sample_model(m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...of bilateral leg veins that was ruled out by inline ) it . had at thistime obtained w / o sign of carotid stenosis which represents anterior ventricular serosanguinous values , no obvious source of infection seen . t_up cxr suggestive of normal superior months.disp:*60 toxins . 2057 and active vs , pulses normal , no focal deficits . per team thought to be due to bloodculture , that is not consistent with an ischemic event and considering slow outpatient monitoring was felt to be secondary to her recent 4:42 ( right sided thigh hypotonic ) . iv access was "
     ]
    }
   ],
   "source": [
    "s = 'blood loss '\n",
    "sample_model(m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
